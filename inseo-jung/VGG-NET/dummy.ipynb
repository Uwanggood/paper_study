{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junginseo/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.label_list = pd.read_csv(csv_file)\n",
    "        self.label_list['name_en'] = self.label_list['name'].astype('category').cat.codes\n",
    "        self.label_list['file_name'] = self.label_list['file_name'].apply(lambda x : x.replace(\" \", \"\"))\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.label_list.iloc[idx]['file_name'])\n",
    "        image = io.imread(img_name)\n",
    "        label = self.label_list.iloc[idx]['name_en']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FaceDataset(csv_file='data/kid_f_train.csv',\n",
    "                                    root_dir='data/HQ_512x512/HQ_512x512/', \n",
    "                                    transform= transform)\n",
    "test_dataset = FaceDataset(csv_file='data/kid_f_test.csv',\n",
    "                            root_dir='data/test_final_with_degrad/test/', \n",
    "                            transform= transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,          # 원래는 별도의 Validation Set의 root 경로를 지정해야 한다. \n",
    "                                          batch_size=20,         # 배치사이즈 지정\n",
    "                                          shuffle=True)           # shuffle 여부 지정\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,          # 원래는 별도의 Validation Set의 root 경로를 지정해야 한다. \n",
    "                                          batch_size=20,         # 배치사이즈 지정\n",
    "                                          shuffle=True)           # shuffle 여부 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class VGG_11(nn.Module):\n",
    "    def __init__(self, num_classes: int = 300, init_weights: bool = True):\n",
    "        super(VGG_11, self).__init__()\n",
    "        self.convnet = nn.Sequential(\n",
    "            # Input Channel (RGB: 3)\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 224 -> 112\n",
    "            \n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 112 -> 56\n",
    "            \n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 56 -> 28\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 28 -> 14\n",
    "\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 14 -> 7\n",
    "        )\n",
    "\n",
    "        self.fclayer = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "            # nn.Softmax(dim=1), # Loss인 Cross Entropy Loss 에서 softmax를 포함한다.\n",
    "        )\n",
    "    \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = self.convnet(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fclayer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class VGG_19(nn.Module):\n",
    "    def __init__(self, num_classes: int = 300, init_weights: bool = True):\n",
    "        super(VGG_19, self).__init__()\n",
    "        self.convnet = nn.Sequential(\n",
    "            # Input Channel (RGB: 3)\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 224 -> 112\n",
    "            \n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 112 -> 56\n",
    "            \n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 56 -> 28\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 28 -> 14\n",
    "\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 14 -> 7\n",
    "        )\n",
    "\n",
    "        self.fclayer = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "            # nn.Softmax(dim=1), # Loss인 Cross Entropy Loss 에서 softmax를 포함한다.\n",
    "        )\n",
    "    \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = self.convnet(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fclayer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    50] loss: 5.698\n",
      "[1,   100] loss: 5.691\n",
      "[1,   150] loss: 5.682\n",
      "[1,   200] loss: 5.674\n",
      "[1,   250] loss: 5.666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [05:33<50:04, 333.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    50] loss: 5.653\n",
      "[2,   100] loss: 5.645\n",
      "[2,   150] loss: 5.637\n",
      "[2,   200] loss: 5.630\n",
      "[2,   250] loss: 5.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [10:59<43:52, 329.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,    50] loss: 5.609\n",
      "[3,   100] loss: 5.601\n",
      "[3,   150] loss: 5.592\n",
      "[3,   200] loss: 5.584\n",
      "[3,   250] loss: 5.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [16:12<37:31, 321.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,    50] loss: 5.564\n",
      "[4,   100] loss: 5.556\n",
      "[4,   150] loss: 5.549\n",
      "[4,   200] loss: 5.539\n",
      "[4,   250] loss: 5.531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [22:00<33:12, 332.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,    50] loss: 5.518\n",
      "[5,   100] loss: 5.511\n",
      "[5,   150] loss: 5.504\n",
      "[5,   200] loss: 5.495\n",
      "[5,   250] loss: 5.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [27:39<27:52, 334.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,    50] loss: 5.475\n",
      "[6,   100] loss: 5.466\n",
      "[6,   150] loss: 5.459\n",
      "[6,   200] loss: 5.454\n",
      "[6,   250] loss: 5.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [33:28<22:38, 339.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,    50] loss: 5.431\n",
      "[7,   100] loss: 5.424\n",
      "[7,   150] loss: 5.415\n",
      "[7,   200] loss: 5.408\n",
      "[7,   250] loss: 5.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [39:10<17:00, 340.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,    50] loss: 5.387\n",
      "[8,   100] loss: 5.379\n",
      "[8,   150] loss: 5.374\n",
      "[8,   200] loss: 5.359\n",
      "[8,   250] loss: 5.357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [44:44<11:16, 338.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,    50] loss: 5.342\n",
      "[9,   100] loss: 5.337\n",
      "[9,   150] loss: 5.327\n",
      "[9,   200] loss: 5.317\n",
      "[9,   250] loss: 5.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [50:06<05:33, 333.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,    50] loss: 5.298\n",
      "[10,   100] loss: 5.293\n",
      "[10,   150] loss: 5.285\n",
      "[10,   200] loss: 5.275\n",
      "[10,   250] loss: 5.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [55:09<00:00, 330.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3309.6829240322113\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'mps'\n",
    "vgg19 = VGG_19()\n",
    "vgg19 = vgg19.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vgg19.parameters(),lr=0.0001)\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in tqdm(range(1000)):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print(inputs.shape)  \n",
    "        outputs= vgg19(inputs)\n",
    "\n",
    "        # print(outputs.shape)\n",
    "        # print(labels.shape)\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 50 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 50))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(time.time()-start_time)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set Accuracy : 0.00%\n"
     ]
    }
   ],
   "source": [
    "vgg19.eval()    # 평가시에는 dropout이 OFF 된다.\n",
    "correct = 0\n",
    "for data, target in test_loader:\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    output = vgg19(data)\n",
    "    prediction = output.data.max(1)[1]\n",
    "    correct += prediction.eq(target.data).sum()\n",
    "print('Test set Accuracy : {:.2f}%'.format(100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('dl_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b7f90f3ffd1b2a60fee91aee39c73355e94a75c9e00035a66944cc7ed4c1221"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
